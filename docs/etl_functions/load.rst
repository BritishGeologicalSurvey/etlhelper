
Load
^^^^

Insert rows
-----------

``execute`` can be used to insert a single row or to execute other
single statements e.g. “CREATE TABLE …”. The ``executemany`` function is
used to insert multiple rows of data. Large datasets are broken into
chunks and inserted in batches to reduce the number of queries. The
INSERT query must container placeholders with an appropriate format for
the input data e.g. positional for tuples, named for dictionaries. The
number of rows that were processed and the number that failed is
returned.

.. code:: python

   from etlhelper import executemany

   rows = [(1, 'value'), (2, 'another value')]
   insert_sql = "INSERT INTO some_table (col1, col2) VALUES (%s, %s)"

   with POSTGRESDB.connect('PGPASSWORD') as conn:
       processed, failed = executemany(insert_sql, conn, rows, chunk_size=1000)

The ``chunk_size`` default is 5,000 and it can be set with a keyword
argument. The ``commit_chunks`` flag defaults to ``True``. This ensures
that an error during a large data transfer doesn’t require all the
records to be sent again. Some work may be required to determine which
records remain to be sent. Setting ``commit_chunks`` to ``False`` will
roll back the entire transfer in case of an error.

Some database engines can return autogenerated values (e.g. primary key
IDs) after INSERT statements. To capture these values, use the
``fetchone`` method to execute the SQL command instead.

.. code:: python

   insert_sql = "INSERT INTO my_table (message) VALUES ('hello') RETURNING id"

   with POSTGRESDB.connect('PGPASSWORD') as conn:
       result = fetchone(insert_sql, conn)

   print(result.id)

The ``load`` function is similar to ``executemany`` except that it
autogenerates an insert query based on the data provided. It uses
``generate_insert_query`` to remove the need to explicitly write the
query for simple cases. By calling this function manually, users can
create a base insert query that can be extended with clauses such as
``ON CONFLICT DO NOTHING``.

NOTE: the ``load`` function uses the first row of data to generate the
list of column for the insert query. If later items in the data contain
extra columns, those columns will not be inserted and no error will be
raised.

As ``generate_insert_query`` creates SQL statements from user-provided
input, it checks the table and column names to ensure that they only
contain valid characters.